{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54a40917",
   "metadata": {
    "id": "54a40917"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "K9noG-HnirN2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9noG-HnirN2",
    "outputId": "56e03f90-2e3a-498d-8ef9-248b2f76bbdc"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "xVFhCtDFjQie",
   "metadata": {
    "id": "xVFhCtDFjQie"
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# # from google.colab import drive\n",
    "\n",
    "# # drive.mount('/content/drive/')\n",
    "\n",
    "# zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/hand gesture dataset1/MP_DATA-75.zip\", 'r')\n",
    "# zip_ref.extractall(\"/tmp\")\n",
    "# zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gwiIKS-UjDAr",
   "metadata": {
    "id": "gwiIKS-UjDAr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e807426",
   "metadata": {
    "id": "0e807426"
   },
   "outputs": [],
   "source": [
    "mp_holistic=mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11a0f2cc",
   "metadata": {
    "id": "11a0f2cc"
   },
   "outputs": [],
   "source": [
    "def mediapipe_detection(image,model):\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable=False\n",
    "    results=model.process(image)\n",
    "    image.flags.writeable=True\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return image,results       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "55c620e1",
   "metadata": {
    "id": "55c620e1"
   },
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "572536b2",
   "metadata": {
    "id": "572536b2"
   },
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76e7fc59",
   "metadata": {
    "id": "76e7fc59"
   },
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0) #laptop webcam\n",
    "# cap=cv2.VideoCapture(1) #mobile\n",
    "# cap=cv2.VideoCapture(2) #mobile2\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        \n",
    "        image,results=mediapipe_detection(frame,holistic)\n",
    "        \n",
    "        draw_styled_landmarks(image,results)\n",
    "        cv2.imshow('OpenCV Feed',image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'or'Q'):\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6cc543e9",
   "metadata": {
    "id": "6cc543e9"
   },
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ed50a234",
   "metadata": {
    "id": "ed50a234"
   },
   "outputs": [],
   "source": [
    "DATA_PATH=os.path.join(\"MP_DATA\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3710a884",
   "metadata": {
    "id": "3710a884"
   },
   "outputs": [],
   "source": [
    "actions=np.array(['Bye','Hello','How Are You','I Love You',\"I'm Fine\",'No','Yes',])\n",
    "no_sequences = 75 #change according to your sequence\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c792894f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15750"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7*75*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3b1956e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26176500"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15750*1662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6aca0243",
   "metadata": {
    "id": "6aca0243"
   },
   "outputs": [],
   "source": [
    "# for action in actions:\n",
    "#     for sequence in range(no_sequences): #change according to your sequence\n",
    "#         try:\n",
    "#             os.makedirs(os.path.join(DATA_PATH,action,str(sequence)))\n",
    "#         except:\n",
    "#                 pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c7ba748",
   "metadata": {
    "id": "3c7ba748"
   },
   "outputs": [],
   "source": [
    "# cap=cv2.VideoCapture(2) #laptop webcam\n",
    "# # cap=cv2.VideoCapture(1) #mobile\n",
    "\n",
    "# y=['Hello','Yes','No' ,'I Love You','Bye','How are you',\"I'm fine\"]\n",
    "# i=0\n",
    "\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "#     for action in actions:\n",
    "#         cv2.putText(image,f\"please change your action to \",(75,200),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),3,cv2.LINE_AA)\n",
    "#         cv2.putText(image,f\"{action} \",(125,250),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),5,cv2.LINE_AA)\n",
    "#         cv2.imshow('OpenCV Feed', image)\n",
    "#         cv2.waitKey(5000)\n",
    "#         for sequence in range(15,no_sequences): #change according to u\n",
    "            \n",
    "#             for frame_num in range(sequence_length):\n",
    "                    \n",
    "#                     ret,frame=cap.read()\n",
    "#                     image,results=mediapipe_detection(frame,holistic)\n",
    "#                     draw_styled_landmarks(image,results)\n",
    "    \n",
    "#                     if frame_num==0:\n",
    "#                             cv2.putText(image,\"Please reset your pose\",(100,200),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)\n",
    "#                             cv2.putText(image,f\"the frame no is {frame_num} the sequence is {sequence+7-no_sequences}\",(2,20),cv2.FONT_HERSHEY_SIMPLEX,0.75,(0,255,0),1,cv2.LINE_AA)\n",
    "#                             cv2.putText(image,f\"action : {action}\",(75,100),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2,cv2.LINE_AA)\n",
    "#                             cv2.imshow('OpenCV Feed', image)\n",
    "#                             cv2.waitKey(2500)\n",
    "#                     else:\n",
    "                        \n",
    "#                         cv2.putText(image,f\"the frame no is {frame_num} the sequence is {sequence+7-no_sequences}\",(2,20),cv2.FONT_HERSHEY_SIMPLEX,0.75,(0,255,0),1,cv2.LINE_AA)\n",
    "#                         cv2.putText(image,f\"action : {action}\",(75,100),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2,cv2.LINE_AA)\n",
    "#                         cv2.imshow('OpenCV Feed', image)\n",
    "                    \n",
    "#                     keypoints=extract_keypoints(results)\n",
    "#                     npy_path=os.path.join(DATA_PATH,action,str(sequence),str(frame_num))\n",
    "#                     np.save(npy_path,keypoints)\n",
    "                    \n",
    "#                     if cv2.waitKey(10) & 0xFF == ord('q'or'Q'):\n",
    "#                             break\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bc3ec8c1",
   "metadata": {
    "id": "bc3ec8c1"
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "24bc9cbd",
   "metadata": {
    "id": "24bc9cbd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5dd74dd6",
   "metadata": {
    "id": "5dd74dd6"
   },
   "outputs": [],
   "source": [
    "label_map={label:num for num,label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "de04a750",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de04a750",
    "outputId": "0b49a230-b706-4e1d-98e9-6bb1b1b2cfea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bye 0\n",
      "Hello 1\n",
      "How Are You 2\n",
      "I Love You 3\n",
      "I'm Fine 4\n",
      "No 5\n",
      "Yes 6\n"
     ]
    }
   ],
   "source": [
    "y=enumerate(actions)\n",
    "for label,num in y:\n",
    "    print(num,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "14f70526",
   "metadata": {
    "id": "14f70526"
   },
   "outputs": [],
   "source": [
    "label_map={label:num for num,label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c8a62382",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8a62382",
    "outputId": "3b2f4b3a-b1c8-44a7-e44c-2716819f1e8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bye': 0, 'Hello': 1, 'How Are You': 2, 'I Love You': 3, \"I'm Fine\": 4, 'No': 5, 'Yes': 6}\n"
     ]
    }
   ],
   "source": [
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "83746f4d",
   "metadata": {
    "id": "83746f4d"
   },
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(0,no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "    # for sequence in range(45,75):\n",
    "    #     for frame_num in range(sequence_length):\n",
    "    #         res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "    #         window.append(res)\n",
    "    #     sequences.append(window)\n",
    "    #     labels.append(label_map[action])\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "778b4e08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "778b4e08",
    "outputId": "883eedd8-9f53-4a61-ff93-55e70fe49541"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 30, 1662)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ce30295d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce30295d",
    "outputId": "5bff64aa-fffc-41d9-fe42-b69bbd29e67c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "39083c6c",
   "metadata": {
    "id": "39083c6c"
   },
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "96e4bd88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96e4bd88",
    "outputId": "d83c65ae-8fde-4948-a200-f171e1ed7158"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 30, 1662)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c9530c2e",
   "metadata": {
    "id": "c9530c2e"
   },
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f24b2a54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f24b2a54",
    "outputId": "d7d954e4-6e48-44ac-be0a-5827fa49586e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b2bce051",
   "metadata": {
    "id": "b2bce051"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b55a212b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b55a212b",
    "outputId": "e5c39436-b4d0-4797-a977-e9054c2ef08d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 7)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0dfbb5f1",
   "metadata": {
    "id": "0dfbb5f1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Dropout,Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2c6455e4",
   "metadata": {
    "id": "2c6455e4"
   },
   "outputs": [],
   "source": [
    "log_dir=os.path.join('Logs')\n",
    "tb_callback=TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8d8449fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d8449fa",
    "outputId": "09e7fbf0-e641-4a10-d71b-da6860a4a6ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(actions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2a6632f5",
   "metadata": {
    "id": "2a6632f5"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(64,return_sequences=True,activation=\"relu\",input_shape=(30,1662)))\n",
    "model.add(LSTM(128,return_sequences=True,activation=\"relu\"))\n",
    "model.add(LSTM(64,return_sequences=False,activation=\"relu\"))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(actions.shape[0],activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "770bb654",
   "metadata": {
    "id": "770bb654"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09a49a12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09a49a12",
    "outputId": "bf2a2761-c54a-41e6-d5f9-76290601d874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 6s 157ms/step - loss: 7.4331 - categorical_accuracy: 0.1571\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.9742 - categorical_accuracy: 0.1340\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.9386 - categorical_accuracy: 0.2182\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.8864 - categorical_accuracy: 0.1910\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 1.7587 - categorical_accuracy: 0.2980\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 1.7728 - categorical_accuracy: 0.2911\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.7913 - categorical_accuracy: 0.2729\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 1.7989 - categorical_accuracy: 0.2450\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.6891 - categorical_accuracy: 0.3247\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.6962 - categorical_accuracy: 0.2958\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 1.6525 - categorical_accuracy: 0.2990\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.6385 - categorical_accuracy: 0.2842\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.9995 - categorical_accuracy: 0.1863\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9438 - categorical_accuracy: 0.1635\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9346 - categorical_accuracy: 0.1439\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 1.8827 - categorical_accuracy: 0.1978\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.9046 - categorical_accuracy: 0.1845\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 1.8636 - categorical_accuracy: 0.2464\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.8707 - categorical_accuracy: 0.1949\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.8067 - categorical_accuracy: 0.2838\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.8154 - categorical_accuracy: 0.2634\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.7671 - categorical_accuracy: 0.2995\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.8063 - categorical_accuracy: 0.2846\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 1.7023 - categorical_accuracy: 0.2706\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.6849 - categorical_accuracy: 0.3245\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.6618 - categorical_accuracy: 0.3292\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.6513 - categorical_accuracy: 0.3062\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.5446 - categorical_accuracy: 0.3608\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 2.2094 - categorical_accuracy: 0.2086\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.9061 - categorical_accuracy: 0.2269\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.7627 - categorical_accuracy: 0.2681\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 1.9110 - categorical_accuracy: 0.2055\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9527 - categorical_accuracy: 0.1117\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9090 - categorical_accuracy: 0.1495\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.7596 - categorical_accuracy: 0.2303\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 2.7190 - categorical_accuracy: 0.2709\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9553 - categorical_accuracy: 0.1596\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.9642 - categorical_accuracy: 0.1264\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 1.9675 - categorical_accuracy: 0.1305\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 1.9527 - categorical_accuracy: 0.1287\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 1.9526 - categorical_accuracy: 0.1391\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 1.9450 - categorical_accuracy: 0.1469\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9515 - categorical_accuracy: 0.1600\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9406 - categorical_accuracy: 0.1527\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9427 - categorical_accuracy: 0.1210\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9376 - categorical_accuracy: 0.1545\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9293 - categorical_accuracy: 0.1330\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9435 - categorical_accuracy: 0.1362\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9294 - categorical_accuracy: 0.1691\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9375 - categorical_accuracy: 0.1634\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9391 - categorical_accuracy: 0.1724\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9631 - categorical_accuracy: 0.1781\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9392 - categorical_accuracy: 0.1826\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9416 - categorical_accuracy: 0.1637\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9430 - categorical_accuracy: 0.1587\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9405 - categorical_accuracy: 0.1915\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9366 - categorical_accuracy: 0.1842\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 1.9367 - categorical_accuracy: 0.1589\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9334 - categorical_accuracy: 0.1775\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9318 - categorical_accuracy: 0.1835\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9255 - categorical_accuracy: 0.1830\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 1.9056 - categorical_accuracy: 0.1389\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 1.9266 - categorical_accuracy: 0.1756\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.9375 - categorical_accuracy: 0.1830\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9366 - categorical_accuracy: 0.1850\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9403 - categorical_accuracy: 0.1627\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 1.9364 - categorical_accuracy: 0.1486\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9369 - categorical_accuracy: 0.1454\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9242 - categorical_accuracy: 0.1812\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.9339 - categorical_accuracy: 0.1548\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9341 - categorical_accuracy: 0.1723\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9382 - categorical_accuracy: 0.1645\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9318 - categorical_accuracy: 0.1846\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9355 - categorical_accuracy: 0.1495\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9367 - categorical_accuracy: 0.1622\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 1.9172 - categorical_accuracy: 0.1729\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9121 - categorical_accuracy: 0.2001\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9233 - categorical_accuracy: 0.1664\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.9300 - categorical_accuracy: 0.2286\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.8992 - categorical_accuracy: 0.2735\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 4.4445 - categorical_accuracy: 0.1469\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9690 - categorical_accuracy: 0.1439\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9302 - categorical_accuracy: 0.1812\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9342 - categorical_accuracy: 0.1890\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 1.9374 - categorical_accuracy: 0.1637\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9328 - categorical_accuracy: 0.1597\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.9343 - categorical_accuracy: 0.1498\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9271 - categorical_accuracy: 0.1513\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 1.9222 - categorical_accuracy: 0.1622\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9142 - categorical_accuracy: 0.1427\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.8964 - categorical_accuracy: 0.1591\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9388 - categorical_accuracy: 0.1584\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9259 - categorical_accuracy: 0.1976\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9420 - categorical_accuracy: 0.1817\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9266 - categorical_accuracy: 0.1778\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9312 - categorical_accuracy: 0.1533\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9409 - categorical_accuracy: 0.1532\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9406 - categorical_accuracy: 0.1330\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 1.9315 - categorical_accuracy: 0.1826\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9250 - categorical_accuracy: 0.1537\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9288 - categorical_accuracy: 0.1626\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9398 - categorical_accuracy: 0.1566\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9416 - categorical_accuracy: 0.1556\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9388 - categorical_accuracy: 0.1426\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 1.9191 - categorical_accuracy: 0.1821\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 1.9325 - categorical_accuracy: 0.1574\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.9296 - categorical_accuracy: 0.1503\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 1.9445 - categorical_accuracy: 0.1253\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.9395 - categorical_accuracy: 0.1656\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.9339 - categorical_accuracy: 0.1798\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9285 - categorical_accuracy: 0.1713\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9350 - categorical_accuracy: 0.1530\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.9327 - categorical_accuracy: 0.1661\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9275 - categorical_accuracy: 0.1713\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.9301 - categorical_accuracy: 0.1990\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9339 - categorical_accuracy: 0.1422\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9321 - categorical_accuracy: 0.1882\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.9269 - categorical_accuracy: 0.1954\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9348 - categorical_accuracy: 0.1603\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9387 - categorical_accuracy: 0.1539\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.9400 - categorical_accuracy: 0.1498\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9411 - categorical_accuracy: 0.1662\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.9352 - categorical_accuracy: 0.1425\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9348 - categorical_accuracy: 0.1447\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.9362 - categorical_accuracy: 0.1550\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.9352 - categorical_accuracy: 0.1702\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.9353 - categorical_accuracy: 0.1685\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9386 - categorical_accuracy: 0.1484\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9333 - categorical_accuracy: 0.1484\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 1.9314 - categorical_accuracy: 0.1880\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9250 - categorical_accuracy: 0.1930 0s - loss: 1.9271 - categorical_\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 1.9151 - categorical_accuracy: 0.2014\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.9384 - categorical_accuracy: 0.1788\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.9351 - categorical_accuracy: 0.1781\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.9333 - categorical_accuracy: 0.1762\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9306 - categorical_accuracy: 0.1592\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9307 - categorical_accuracy: 0.1470\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.9312 - categorical_accuracy: 0.1737\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9364 - categorical_accuracy: 0.1502\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.9374 - categorical_accuracy: 0.1699\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9401 - categorical_accuracy: 0.1710\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9264 - categorical_accuracy: 0.1956\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9344 - categorical_accuracy: 0.1659\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9451 - categorical_accuracy: 0.1482\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9364 - categorical_accuracy: 0.1601\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9319 - categorical_accuracy: 0.1638\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9347 - categorical_accuracy: 0.1508\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9282 - categorical_accuracy: 0.1655\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9244 - categorical_accuracy: 0.1729\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.9402 - categorical_accuracy: 0.1736\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9403 - categorical_accuracy: 0.1568\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9315 - categorical_accuracy: 0.1741\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 1.9354 - categorical_accuracy: 0.1482\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9397 - categorical_accuracy: 0.1621\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 1.9367 - categorical_accuracy: 0.1576\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 1.9276 - categorical_accuracy: 0.1643\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9333 - categorical_accuracy: 0.1754 0s - loss: 1.9333 - categorical_accuracy: 0.17\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9339 - categorical_accuracy: 0.1647\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.9321 - categorical_accuracy: 0.1711\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9295 - categorical_accuracy: 0.1708\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9382 - categorical_accuracy: 0.1642\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.9424 - categorical_accuracy: 0.1510\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9385 - categorical_accuracy: 0.1537\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9364 - categorical_accuracy: 0.1558\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9313 - categorical_accuracy: 0.1649\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 1.9364 - categorical_accuracy: 0.1589\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9240 - categorical_accuracy: 0.1445\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9424 - categorical_accuracy: 0.1653\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9313 - categorical_accuracy: 0.1892\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9337 - categorical_accuracy: 0.1361\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9188 - categorical_accuracy: 0.1978\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9384 - categorical_accuracy: 0.1813\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 1.9363 - categorical_accuracy: 0.1730\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9377 - categorical_accuracy: 0.1363\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9416 - categorical_accuracy: 0.1624\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 1.9319 - categorical_accuracy: 0.1719\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9296 - categorical_accuracy: 0.1765\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 1.9381 - categorical_accuracy: 0.1562\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9171 - categorical_accuracy: 0.2008\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 1.9377 - categorical_accuracy: 0.1580\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9272 - categorical_accuracy: 0.1644\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 1.9173 - categorical_accuracy: 0.1782\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9325 - categorical_accuracy: 0.1749\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 1.9250 - categorical_accuracy: 0.1796\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9307 - categorical_accuracy: 0.1742\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 1.9331 - categorical_accuracy: 0.1537\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.9334 - categorical_accuracy: 0.1824\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1.9349 - categorical_accuracy: 0.1838\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 1.9348 - categorical_accuracy: 0.1729\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9360 - categorical_accuracy: 0.1925\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 1.9414 - categorical_accuracy: 0.1542\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 1.9267 - categorical_accuracy: 0.1670\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 1.9327 - categorical_accuracy: 0.1611\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 1.9377 - categorical_accuracy: 0.1497\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 1.9254 - categorical_accuracy: 0.1917\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 1s 106ms/step - loss: 1.9328 - categorical_accuracy: 0.1779\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 1.9192 - categorical_accuracy: 0.1809\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 1s 112ms/step - loss: 1.9279 - categorical_accuracy: 0.1548\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 1.9311 - categorical_accuracy: 0.1662\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 1.9263 - categorical_accuracy: 0.1988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20487390400>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(X_train,y_train,epochs=200,callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b25b52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0b25b52",
    "outputId": "d8d00175-de4a-4458-9dcc-b971833c4bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_17 (LSTM)              (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 30, 128)           0         \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596,807\n",
      "Trainable params: 596,807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fbea12c3",
   "metadata": {
    "id": "fbea12c3"
   },
   "outputs": [],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b82ea60c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "b82ea60c",
    "outputId": "c3334f4b-13f4-4c00-a2a0-388f4522b06d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7819cc35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7819cc35",
    "outputId": "19a807b7-293e-472d-d54f-b72e773064eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9d28dd5f",
   "metadata": {
    "id": "9d28dd5f"
   },
   "outputs": [],
   "source": [
    "model.save(\"handGes2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "85676a24",
   "metadata": {
    "id": "85676a24"
   },
   "outputs": [],
   "source": [
    "model.load_weights('handGes1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f2e11597",
   "metadata": {
    "id": "f2e11597",
    "outputId": "b03b34b3-d3f2-4e72-dd87-b66065afa795"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[171,  59],\n",
       "        [ 17,  16]],\n",
       "\n",
       "       [[218,  14],\n",
       "        [ 10,  21]],\n",
       "\n",
       "       [[213,   3],\n",
       "        [  8,  39]],\n",
       "\n",
       "       [[194,  37],\n",
       "        [ 25,   7]],\n",
       "\n",
       "       [[211,   7],\n",
       "        [ 35,  10]],\n",
       "\n",
       "       [[219,   6],\n",
       "        [ 38,   0]],\n",
       "\n",
       "       [[193,  33],\n",
       "        [ 26,  11]]], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9876202d",
   "metadata": {
    "id": "9876202d",
    "outputId": "ea5360e6-5ec7-4088-90f4-c326c4ee84e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39543726235741444"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "edbfa76f",
   "metadata": {
    "id": "edbfa76f"
   },
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "356d9557",
   "metadata": {
    "id": "356d9557"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(18,18))\n",
    "# plt.imshow(prob_viz(res, actions, image, colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4cd885f9",
   "metadata": {
    "id": "4cd885f9",
    "outputId": "59d1d543-9c98-4ef5-82d5-4cd8eac2abc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "Hello\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-e59e493d2c5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;31m# Viz probabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprob_viz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m245\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m117\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-123-e9bc22b256b7>\u001b[0m in \u001b[0;36mprob_viz\u001b[1;34m(res, actions, input_frame, colors)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0moutput_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m90\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m85\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLINE_AA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.8\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "#         sequence.insert(0,keypoints)\n",
    "#         sequence = sequence[:30]\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            \n",
    "            \n",
    "        #3. Viz logic\n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                if len(sentence) > 0: \n",
    "                    if actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                else:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc2bf8",
   "metadata": {
    "id": "6bbc2bf8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Copy of hand gesture.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
